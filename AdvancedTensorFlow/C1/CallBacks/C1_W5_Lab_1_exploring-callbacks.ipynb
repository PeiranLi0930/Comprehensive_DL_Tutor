{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c_TYhQOUe1j"
   },
   "source": [
    "# Ungraded Lab: Introduction to Keras callbacks\n",
    "\n",
    "In Keras, `Callback` is a Python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training. The methods of the callbacks can  be called at different stages of training/evaluating/inference. Keras has available [callbacks](https://keras.io/api/callbacks/) and we'll show how you can use it in the following sections. Please click the **Open in Colab** badge above to complete this exercise in Colab. This will allow you to take advantage of the free GPU runtime (for faster training) and compatibility with all the packages needed in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uyl69EyRQx-f"
   },
   "source": [
    "## Model methods that take callbacks\n",
    "Users can supply a list of callbacks to the following `tf.keras.Model` methods:\n",
    "* [`fit()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit), [`fit_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator)\n",
    "Trains the model for a fixed number of epochs (iterations over a dataset, or data yielded batch-by-batch by a Python generator).\n",
    "* [`evaluate()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate), [`evaluate_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate_generator)\n",
    "Evaluates the model for given data or data generator. Outputs the loss and metric values from the evaluation.\n",
    "* [`predict()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict), [`predict_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict_generator)\n",
    "Generates output predictions for the input data or data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlT1Kh3uA9lZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.9.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnSljqtsXKfb"
   },
   "source": [
    "# Examples of Keras callback applications\n",
    "The following section will guide you through creating simple [Callback](https://keras.io/api/callbacks/) applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spskRuxvCYQE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset horses_or_humans (153.59 MiB) to /Users/lipeiran/tensorflow_datasets/horses_or_humans/1.0.0...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da339d4314e248389ec3d653c6e6edd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a3db5fa0ad149f98d1e2e6fd49c9bb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipeiran/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/lipeiran/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "Failed to get url https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip. HTTP code: 404.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mDownloadError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Download and prepare the horses or humans dataset\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# horses_or_humans 3.0.0 has already been downloaded for you\u001B[39;00m\n\u001B[1;32m      4\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./tensorflow_datasets\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 5\u001B[0m splits, info \u001B[38;5;241m=\u001B[39m \u001B[43mtfds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhorses_or_humans\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_supervised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain[:80\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m]\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain[80\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m:]\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m (train_examples, validation_examples, test_examples) \u001B[38;5;241m=\u001B[39m splits\n\u001B[1;32m      9\u001B[0m num_examples \u001B[38;5;241m=\u001B[39m info\u001B[38;5;241m.\u001B[39msplits[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mnum_examples\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/api_utils.py:52\u001B[0m, in \u001B[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001B[0;34m(fn, instance, args, kwargs)\u001B[0m\n\u001B[1;32m     50\u001B[0m _check_no_positional(fn, args, ismethod, allowed\u001B[38;5;241m=\u001B[39mallowed)\n\u001B[1;32m     51\u001B[0m _check_required(fn, kwargs)\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py:300\u001B[0m, in \u001B[0;36mload\u001B[0;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[1;32m    299\u001B[0m   download_and_prepare_kwargs \u001B[38;5;241m=\u001B[39m download_and_prepare_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[0;32m--> 300\u001B[0m   \u001B[43mdbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m as_dataset_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    303\u001B[0m   as_dataset_kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/api_utils.py:52\u001B[0m, in \u001B[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001B[0;34m(fn, instance, args, kwargs)\u001B[0m\n\u001B[1;32m     50\u001B[0m _check_no_positional(fn, args, ismethod, allowed\u001B[38;5;241m=\u001B[39mallowed)\n\u001B[1;32m     51\u001B[0m _check_required(fn, kwargs)\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:285\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[0;34m(self, download_dir, download_config)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m file_format_adapter\u001B[38;5;241m.\u001B[39mincomplete_dir(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_dir) \u001B[38;5;28;01mas\u001B[39;00m tmp_data_dir:\n\u001B[1;32m    282\u001B[0m   \u001B[38;5;66;03m# Temporarily assign _data_dir to tmp_data_dir to avoid having to forward\u001B[39;00m\n\u001B[1;32m    283\u001B[0m   \u001B[38;5;66;03m# it to every sub function.\u001B[39;00m\n\u001B[1;32m    284\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mtemporary_assignment(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_data_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m, tmp_data_dir):\n\u001B[0;32m--> 285\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001B[39;00m\n\u001B[1;32m    290\u001B[0m     \u001B[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001B[39;00m\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001B[39;00m\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;66;03m# when reading from package data.\u001B[39;00m\n\u001B[1;32m    293\u001B[0m \n\u001B[1;32m    294\u001B[0m     \u001B[38;5;66;03m# Update the DatasetInfo metadata by computing statistics from the data.\u001B[39;00m\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (download_config\u001B[38;5;241m.\u001B[39mcompute_stats \u001B[38;5;241m==\u001B[39m download\u001B[38;5;241m.\u001B[39mComputeStatsMode\u001B[38;5;241m.\u001B[39mSKIP \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m    296\u001B[0m         download_config\u001B[38;5;241m.\u001B[39mcompute_stats \u001B[38;5;241m==\u001B[39m download\u001B[38;5;241m.\u001B[39mComputeStatsMode\u001B[38;5;241m.\u001B[39mAUTO \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    297\u001B[0m         \u001B[38;5;28mbool\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39msplits\u001B[38;5;241m.\u001B[39mtotal_num_examples)\n\u001B[1;32m    298\u001B[0m        ):\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:946\u001B[0m, in \u001B[0;36mGeneratorBasedBuilder._download_and_prepare\u001B[0;34m(self, dl_manager, download_config)\u001B[0m\n\u001B[1;32m    944\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_download_and_prepare\u001B[39m(\u001B[38;5;28mself\u001B[39m, dl_manager, download_config):\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# Extract max_examples_per_split and forward it to _prepare_split\u001B[39;00m\n\u001B[0;32m--> 946\u001B[0m   \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mGeneratorBasedBuilder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    947\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    948\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmax_examples_per_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_examples_per_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:804\u001B[0m, in \u001B[0;36mFileAdapterBuilder._download_and_prepare\u001B[0;34m(self, dl_manager, **prepare_split_kwargs)\u001B[0m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Generating data for all splits\u001B[39;00m\n\u001B[1;32m    803\u001B[0m split_dict \u001B[38;5;241m=\u001B[39m splits_lib\u001B[38;5;241m.\u001B[39mSplitDict()\n\u001B[0;32m--> 804\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m split_generator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_split_generators\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    805\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m splits_lib\u001B[38;5;241m.\u001B[39mSplit\u001B[38;5;241m.\u001B[39mALL \u001B[38;5;241m==\u001B[39m split_generator\u001B[38;5;241m.\u001B[39msplit_info\u001B[38;5;241m.\u001B[39mname:\n\u001B[1;32m    806\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    807\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtfds.Split.ALL is a special split keyword corresponding to the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    808\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munion of all splits, so cannot be used as key in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    809\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m._split_generator().\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    810\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/image/horses_or_humans.py:73\u001B[0m, in \u001B[0;36mHorsesOrHumans._split_generators\u001B[0;34m(self, dl_manager)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_split_generators\u001B[39m(\u001B[38;5;28mself\u001B[39m, dl_manager):\n\u001B[0;32m---> 73\u001B[0m   train_path, test_path \u001B[38;5;241m=\u001B[39m \u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m_TRAIN_URL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_TEST_URL\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m     76\u001B[0m       tfds\u001B[38;5;241m.\u001B[39mcore\u001B[38;5;241m.\u001B[39mSplitGenerator(\n\u001B[1;32m     77\u001B[0m           name\u001B[38;5;241m=\u001B[39mtfds\u001B[38;5;241m.\u001B[39mSplit\u001B[38;5;241m.\u001B[39mTRAIN,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     87\u001B[0m           }),\n\u001B[1;32m     88\u001B[0m   ]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/download/download_manager.py:301\u001B[0m, in \u001B[0;36mDownloadManager.download\u001B[0;34m(self, url_or_urls)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;66;03m# Add progress bar to follow the download state\u001B[39;00m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_downloader\u001B[38;5;241m.\u001B[39mtqdm():\n\u001B[0;32m--> 301\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_map_promise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl_or_urls\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/download/download_manager.py:395\u001B[0m, in \u001B[0;36m_map_promise\u001B[0;34m(map_fn, all_inputs)\u001B[0m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001B[39;00m\n\u001B[1;32m    394\u001B[0m all_promises \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mmap_nested(map_fn, all_inputs)  \u001B[38;5;66;03m# Apply the function\u001B[39;00m\n\u001B[0;32m--> 395\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_wait_on_promise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_promises\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/utils/py_utils.py:136\u001B[0m, in \u001B[0;36mmap_nested\u001B[0;34m(function, data_struct, dict_only, map_tuple)\u001B[0m\n\u001B[1;32m    134\u001B[0m   types\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mtuple\u001B[39m)\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mtuple\u001B[39m(types)):\n\u001B[0;32m--> 136\u001B[0m   mapped \u001B[38;5;241m=\u001B[39m [map_nested(function, v, dict_only, map_tuple)\n\u001B[1;32m    137\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m data_struct]\n\u001B[1;32m    138\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mapped\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/utils/py_utils.py:136\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    134\u001B[0m   types\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mtuple\u001B[39m)\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mtuple\u001B[39m(types)):\n\u001B[0;32m--> 136\u001B[0m   mapped \u001B[38;5;241m=\u001B[39m [\u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_tuple\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m data_struct]\n\u001B[1;32m    138\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mapped\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/utils/py_utils.py:143\u001B[0m, in \u001B[0;36mmap_nested\u001B[0;34m(function, data_struct, dict_only, map_tuple)\u001B[0m\n\u001B[1;32m    141\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(mapped)\n\u001B[1;32m    142\u001B[0m \u001B[38;5;66;03m# Singleton\u001B[39;00m\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/download/download_manager.py:379\u001B[0m, in \u001B[0;36m_wait_on_promise\u001B[0;34m(p)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wait_on_promise\u001B[39m(p):\n\u001B[0;32m--> 379\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/promise/promise.py:512\u001B[0m, in \u001B[0;36mPromise.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    510\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_target()\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait(timeout \u001B[38;5;129;01mor\u001B[39;00m DEFAULT_TIMEOUT)\n\u001B[0;32m--> 512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_target_settled_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_raise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/promise/promise.py:516\u001B[0m, in \u001B[0;36mPromise._target_settled_value\u001B[0;34m(self, _raise)\u001B[0m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_target_settled_value\u001B[39m(\u001B[38;5;28mself\u001B[39m, _raise\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;66;03m# type: (bool) -> Any\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_settled_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_raise\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/promise/promise.py:226\u001B[0m, in \u001B[0;36mPromise._settled_value\u001B[0;34m(self, _raise)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _raise:\n\u001B[1;32m    225\u001B[0m     raise_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fulfillment_handler0\n\u001B[0;32m--> 226\u001B[0m     \u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mraise_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraise_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_traceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fulfillment_handler0\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/six.py:719\u001B[0m, in \u001B[0;36mreraise\u001B[0;34m(tp, value, tb)\u001B[0m\n\u001B[1;32m    717\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[1;32m    718\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[0;32m--> 719\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\n\u001B[1;32m    720\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    721\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/promise/promise.py:844\u001B[0m, in \u001B[0;36m_process_future_result.<locals>.handle_future_result\u001B[0;34m(future)\u001B[0m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandle_future_result\u001B[39m(future):\n\u001B[1;32m    842\u001B[0m     \u001B[38;5;66;03m# type: (Any) -> None\u001B[39;00m\n\u001B[1;32m    843\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 844\u001B[0m         resolve(\u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    845\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    846\u001B[0m         tb \u001B[38;5;241m=\u001B[39m exc_info()[\u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/concurrent/futures/_base.py:438\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/concurrent/futures/thread.py:52\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 52\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Matrix-in-Machine-Learning/lib/python3.10/site-packages/tensorflow_datasets/core/download/downloader.py:233\u001B[0m, in \u001B[0;36m_Downloader._sync_download\u001B[0;34m(self, url, destination_path)\u001B[0m\n\u001B[1;32m    231\u001B[0m   response \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mget(url, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    232\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m--> 233\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DownloadError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed to get url \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m. HTTP code: \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m    234\u001B[0m                         (url, response\u001B[38;5;241m.\u001B[39mstatus_code))\n\u001B[1;32m    235\u001B[0m fname \u001B[38;5;241m=\u001B[39m _get_filename(response)\n\u001B[1;32m    236\u001B[0m path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(destination_path, fname)\n",
      "\u001B[0;31mDownloadError\u001B[0m: Failed to get url https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip. HTTP code: 404."
     ]
    }
   ],
   "source": [
    "# Download and prepare the horses or humans dataset\n",
    "\n",
    "# horses_or_humans 3.0.0 has already been downloaded for you\n",
    "path = \"./tensorflow_datasets\"\n",
    "splits, info = tfds.load('horses_or_humans', as_supervised=True, with_info=True, split=['train[:80%]', 'train[80%:]', 'test'])\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veIsubKTCZsN"
   },
   "outputs": [],
   "source": [
    "SIZE = 150 #@param {type:\"slider\", min:64, max:300, step:1}\n",
    "IMAGE_SIZE = (SIZE, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faajLlErCb1S"
   },
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "  return  image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVXPuU12Cdka"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lHDkFVaCe48"
   },
   "outputs": [],
   "source": [
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxsCqEIkCgUt"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "  pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDBpWvHXCh2A"
   },
   "outputs": [],
   "source": [
    "def build_model(dense_units, input_shape=IMAGE_SIZE + (3,)):\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(dense_units, activation='relu'),\n",
    "      tf.keras.layers.Dense(2, activation='softmax')\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZKGkjagENSw"
   },
   "source": [
    "## [TensorBoard](https://keras.io/api/callbacks/tensorboard/)\n",
    "\n",
    "Enable visualizations for TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeiD2WVEHbex"
   },
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpLwPLnAEOzv"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=10, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJunWOjZE0ir"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv9H4Pc2Mfl7"
   },
   "source": [
    "## [Model Checkpoint](https://keras.io/api/callbacks/model_checkpoint/)\n",
    "\n",
    "Callback to save the Keras model or model weights at some frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYV4FJ8iMmDq"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.h5', verbose=1),\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGvjQ8IlMmK6"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=1, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('saved_model', verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1ConwoB0EjD"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=2, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('model.h5', verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kptNF0--Lznv"
   },
   "source": [
    "## [Early stopping](https://keras.io/api/callbacks/early_stopping/)\n",
    "\n",
    "Stop training when a monitored metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJOJTJYdCkdY"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=50, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[EarlyStopping(\n",
    "              patience=3,\n",
    "              min_delta=0.05,\n",
    "              baseline=0.8,\n",
    "              mode='min',\n",
    "              monitor='val_loss',\n",
    "              restore_best_weights=True,\n",
    "              verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mDzWUD4Pqq5"
   },
   "source": [
    "## [CSV Logger](https://keras.io/api/callbacks/csv_logger/)\n",
    "\n",
    "Callback that streams epoch results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cffnMpmGPtMh"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "csv_file = 'training.csv'\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[CSVLogger(csv_file)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9tkYi03QV7R"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(csv_file).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dt9C2Y9fRBKN"
   },
   "source": [
    "## [Learning Rate Scheduler](https://keras.io/api/callbacks/learning_rate_scheduler/)\n",
    "\n",
    "Updates the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJi-xY2VRC03"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "def step_decay(epoch):\n",
    "\tinitial_lr = 0.01\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 1\n",
    "\tlr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lr\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[LearningRateScheduler(step_decay, verbose=1),\n",
    "                    TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2S4n8nrbV91"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0wcuQyJE_UK"
   },
   "source": [
    "## [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/)\n",
    "\n",
    "Reduce learning rate when a metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4naxZ-eCFB27"
   },
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=50, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[ReduceLROnPlateau(monitor='val_loss', \n",
    "                                       factor=0.2, verbose=1,\n",
    "                                       patience=1, min_lr=0.001),\n",
    "                     TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isfTWP4NYudk"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir log_dir"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExploringCallbacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}